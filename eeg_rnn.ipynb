{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":11663436,"datasetId":7313426,"databundleVersionId":12134098}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport h5py\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:34:56.815498Z","iopub.execute_input":"2025-05-03T19:34:56.815779Z","iopub.status.idle":"2025-05-03T19:34:56.820430Z","shell.execute_reply.started":"2025-05-03T19:34:56.815758Z","shell.execute_reply":"2025-05-03T19:34:56.819642Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:38:22.284760Z","iopub.execute_input":"2025-05-03T19:38:22.285432Z","iopub.status.idle":"2025-05-03T19:38:22.291794Z","shell.execute_reply.started":"2025-05-03T19:38:22.285409Z","shell.execute_reply":"2025-05-03T19:38:22.291118Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"labels_df = pd.read_csv('/kaggle/input/bci-rnn-raw-data/TrainLabels.csv')\nlabels = labels_df['Prediction'].to_numpy()\nprint(labels.shape, len(labels))\nlabel_stats = np.unique(labels, return_counts=True)\nprint(label_stats)\nprint(label_stats[1][1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:35:00.482049Z","iopub.execute_input":"2025-05-03T19:35:00.482605Z","iopub.status.idle":"2025-05-03T19:35:00.501110Z","shell.execute_reply.started":"2025-05-03T19:35:00.482572Z","shell.execute_reply":"2025-05-03T19:35:00.500515Z"}},"outputs":[{"name":"stdout","text":"(5440,) 5440\n(array([0, 1]), array([1590, 3850]))\n3850\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"class EEGAugment:\n    def __call__(self, x):\n        # x shape: (channels, time)\n        if random.random() > 0.5:\n            x += torch.randn_like(x) * 0.01  # Gaussian noise\n        if random.random() > 0.5:\n            x = torch.roll(x, shifts=random.randint(-10,10), dims=1)  # Time shift\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:35:02.272735Z","iopub.execute_input":"2025-05-03T19:35:02.273127Z","iopub.status.idle":"2025-05-03T19:35:02.277710Z","shell.execute_reply.started":"2025-05-03T19:35:02.273102Z","shell.execute_reply":"2025-05-03T19:35:02.277137Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"TRAIN_DATA_PATH = '/kaggle/input/bci-rnn-raw-data/rnn_data/rnn_data/eeg_train_data.h5'\n\nclass EEGDataset(Dataset):\n    def __init__(self, path, labels, segment_names=['green', 'blinking', 'feedback']):\n        self.path = path\n        self.labels = labels\n        self.segment_names = segment_names\n        \n        # Verify data consistency on initialization\n        with h5py.File(path, 'r') as f:\n            self.num_trials = len(f[segment_names[0]])  # All groups should have same length\n            for name in segment_names:\n                assert len(f[name]) == self.num_trials, f\"Mismatched trial counts in {name} group\"\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        with h5py.File(self.path, 'r') as f:\n            segments = []\n            for name in self.segment_names:\n                seg_data = f[name][str(idx)][:]  \n                seg_data = np.squeeze(seg_data) # remove if there's a dim of 1\n\n                # Ensure shape is (n_channels, n_samples)\n                if seg_data.ndim == 1:\n                    seg_data = seg_data[np.newaxis, :]  # If single channel\n                \n                seg_data = (seg_data - np.mean(seg_data, axis=1, keepdims=True)) / (np.std(seg_data, axis=1, keepdims=True) + 1e-6)  # Avoid division by zero\n                \n                segments.append(torch.FloatTensor(seg_data))\n            \n            label = torch.tensor(self.labels[idx], dtype=torch.float32)\n            # Assuming you'll add labels later\n            return (*segments, label)  # (green_tensor, blinking_tensor, feedback_tensor, label_tensor)\n\ndef collate_fn(batch):\n    \"\"\"Handles variable-length segments and labels\"\"\"\n    \n    # Verify and correct shapes before processing\n    processed_batch = []\n    for item in batch:\n        # Ensure each segment has shape (n_channels, n_samples)\n        corrected_item = []\n        for seg in item[:3]:  # For each of the 3 segments\n            if seg.dim() == 3:\n                seg = seg.squeeze(0)  # Remove batch dimension if present\n            corrected_item.append(seg)\n        corrected_item.append(item[3])  # Keep label unchanged\n        processed_batch.append(tuple(corrected_item))\n    \n    # Now process with corrected shapes\n    green_segs = [item[0].permute(1, 0) for item in processed_batch]\n    blink_segs = [item[1].permute(1, 0) for item in processed_batch]\n    feedback_segs = [item[2].permute(1, 0) for item in processed_batch]\n    labels = torch.stack([item[3] for item in processed_batch])\n    \n    # Pad each segment type\n    green_padded = pad_sequence(green_segs, batch_first=True).permute(0, 2, 1)\n    blink_padded = pad_sequence(blink_segs, batch_first=True).permute(0, 2, 1)\n    feedback_padded = pad_sequence(feedback_segs, batch_first=True).permute(0, 2, 1)\n    \n    return green_padded, blink_padded, feedback_padded, labels\n\ndataset = EEGDataset(TRAIN_DATA_PATH, labels)\ndataloader = DataLoader(\n    dataset,\n    batch_size=32,\n    collate_fn=collate_fn,\n    shuffle=True,\n    num_workers=2  # If using Kaggle GPU\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:38:33.738760Z","iopub.execute_input":"2025-05-03T19:38:33.739085Z","iopub.status.idle":"2025-05-03T19:38:40.174596Z","shell.execute_reply.started":"2025-05-03T19:38:33.739064Z","shell.execute_reply":"2025-05-03T19:38:40.174000Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"len(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:35:14.624382Z","iopub.execute_input":"2025-05-03T19:35:14.624662Z","iopub.status.idle":"2025-05-03T19:35:14.629693Z","shell.execute_reply.started":"2025-05-03T19:35:14.624642Z","shell.execute_reply":"2025-05-03T19:35:14.629001Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"5440"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"dataset[8][2].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:35:18.568480Z","iopub.execute_input":"2025-05-03T19:35:18.569190Z","iopub.status.idle":"2025-05-03T19:35:18.676304Z","shell.execute_reply.started":"2025-05-03T19:35:18.569169Z","shell.execute_reply":"2025-05-03T19:35:18.675459Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1058351374.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/2583595143.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEEGAugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Assuming you'll add labels later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (green_tensor, blinking_tensor, feedback_tensor, label_tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2938673677.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# x shape: (channels, time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m  \u001b[0;31m# Gaussian noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Time shift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: randn_like(): argument 'input' (position 1) must be Tensor, not list"],"ename":"TypeError","evalue":"randn_like(): argument 'input' (position 1) must be Tensor, not list","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"# Split indices (stratified by labels)\ntrain_idx, val_idx = train_test_split(\n    range(len(dataset)),\n    test_size=0.2,\n    stratify=labels,  # Important for imbalanced classes\n    random_state=42\n)\n\ntrain_loader = DataLoader(\n    Subset(dataset, train_idx),\n    batch_size=32,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=2\n)\n\nval_loader = DataLoader(\n    Subset(dataset, val_idx),\n    batch_size=32,\n    shuffle=False,\n    collate_fn=collate_fn,\n    num_workers=2\n)\n\n# 4. Verify\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:25:38.597453Z","iopub.execute_input":"2025-05-03T17:25:38.598002Z","iopub.status.idle":"2025-05-03T17:25:38.611147Z","shell.execute_reply.started":"2025-05-03T17:25:38.597976Z","shell.execute_reply":"2025-05-03T17:25:38.610313Z"}},"outputs":[{"name":"stdout","text":"Train batches: 136\nVal batches: 34\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"class EEGRNN(nn.Module):\n    # input_dim = number of channels\n    def __init__(self, input_dim=16, hidden_dim=64, num_layers=2, dropout=0.3):\n        super().__init__()\n        self.rnn = nn.GRU(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            bidirectional=True,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim*2, 32),  # *2 for bidirectional\n            nn.ReLU(),\n            nn.Linear(32, 1),\n            nn.Sigmoid()  # Output probabilities\n        )\n\n    def forward(self, x, lengths=None):\n        # x shape: (batch, channels, seq_len)\n        x = x.permute(0, 2, 1)  # (batch, seq_len, channels)\n        \n        if lengths is not None:\n            # Pack padded sequences if lengths are provided\n            x = nn.utils.rnn.pack_padded_sequence(\n                x, lengths.cpu(), batch_first=True, enforce_sorted=False\n            )\n        \n        _, hidden = self.rnn(x)  # hidden: (num_layers*2, batch, hidden_dim)\n        \n        # Concatenate last hidden states from both directions\n        hidden = hidden.view(self.rnn.num_layers, 2, -1, self.rnn.hidden_size)\n        last_hidden = torch.cat([hidden[-1, 0], hidden[-1, 1]], dim=1)\n        \n        return self.classifier(self.dropout(last_hidden)).squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:25:48.277904Z","iopub.execute_input":"2025-05-03T17:25:48.278176Z","iopub.status.idle":"2025-05-03T17:25:48.284781Z","shell.execute_reply.started":"2025-05-03T17:25:48.278158Z","shell.execute_reply":"2025-05-03T17:25:48.284195Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nmodel = EEGRNN(input_dim=16, hidden_dim=32, dropout=0.1).to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n\n#criterion = nn.BCELoss()  # Binary cross-entropy for probabilities\n# Calculate class weights\nclass_weights = torch.tensor([label_stats[1][1]/label_stats[1][0], 1.0], dtype=torch.float32).to(device)  # [2.42, 1.0]\n\n# Modify your loss function\ncriterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[0])  # Automatic weighting\n\n# Learning rate scheduler\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='max', factor=0.5, patience=3, verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:57:30.536392Z","iopub.execute_input":"2025-05-03T17:57:30.537118Z","iopub.status.idle":"2025-05-03T17:57:30.548045Z","shell.execute_reply.started":"2025-05-03T17:57:30.537092Z","shell.execute_reply":"2025-05-03T17:57:30.547287Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def train_epoch(model, loader):\n    model.train()\n    total_loss = 0\n    for green, blink, feedback, labels in loader:\n        # Use whichever segment type performs best (start with feedback)\n        inputs = feedback.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\ndef validate(model, loader):\n    model.eval()\n    all_probs = []\n    all_labels = []\n    with torch.no_grad():\n        for green, blink, feedback, labels in loader:\n            inputs = feedback.to(device)\n            outputs = model(inputs).cpu().numpy()\n            all_probs.extend(outputs)\n            all_labels.extend(labels.numpy())\n    return roc_auc_score(all_labels, all_probs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:57:33.768654Z","iopub.execute_input":"2025-05-03T17:57:33.768912Z","iopub.status.idle":"2025-05-03T17:57:33.774454Z","shell.execute_reply.started":"2025-05-03T17:57:33.768895Z","shell.execute_reply":"2025-05-03T17:57:33.773833Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"Try|Best Score|Loss\n:-:|:-:|:-:\n1|0.5686|0.6064\n2|0.5448|0.9794\n3|0.5109|1.0721","metadata":{}},{"cell_type":"code","source":"NUM_EPOCHS = 15\nMODEL_PATH = '/kaggle/working/best_model_try2.pth'\n\nbest_auc = 0\nfor epoch in range(NUM_EPOCHS):\n    train_loss = train_epoch(model, train_loader)\n    val_auc = validate(model, val_loader)\n    scheduler.step(val_auc)\n    \n    print(f\"Epoch {epoch+1}: Loss={train_loss:.4f}, Val AUC={val_auc:.4f}\")\n    \n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), MODEL_PATH)\n        print(\"↳ New best model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:14:59.726163Z","iopub.execute_input":"2025-05-03T18:14:59.726875Z","iopub.status.idle":"2025-05-03T18:46:41.806396Z","shell.execute_reply.started":"2025-05-03T18:14:59.726848Z","shell.execute_reply":"2025-05-03T18:46:41.805429Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Loss=0.9794, Val AUC=0.5448\n↳ New best model saved!\nEpoch 2: Loss=0.9286, Val AUC=0.5448\nEpoch 3: Loss=0.9229, Val AUC=0.5428\nEpoch 4: Loss=0.9217, Val AUC=0.5413\nEpoch 5: Loss=0.9213, Val AUC=0.5396\nEpoch 6: Loss=0.9211, Val AUC=0.5391\nEpoch 7: Loss=0.9211, Val AUC=0.5389\nEpoch 8: Loss=0.9210, Val AUC=0.5383\nEpoch 9: Loss=0.9209, Val AUC=0.5380\nEpoch 10: Loss=0.9209, Val AUC=0.5379\nEpoch 11: Loss=0.9209, Val AUC=0.5376\nEpoch 12: Loss=0.9209, Val AUC=0.5376\nEpoch 13: Loss=0.9209, Val AUC=0.5373\nEpoch 14: Loss=0.9208, Val AUC=0.5371\nEpoch 15: Loss=0.9208, Val AUC=0.5369\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"batch = next(iter(train_loader))\ngreen, blink, feedback, labels_t = batch\nprint(\"Feedback segment stats:\")\nprint(f\"Shape: {feedback.shape}\")\nprint(f\"Mean: {feedback.mean():.4f}, Std: {feedback.std():.4f}\")\nprint(f\"Min: {feedback.min():.4f}, Max: {feedback.max():.4f}\")\nprint(f\"Label ratio: {labels_t.sum()/len(labels_t):.2%} positive\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:06:38.716386Z","iopub.execute_input":"2025-05-03T19:06:38.716700Z","iopub.status.idle":"2025-05-03T19:06:41.947455Z","shell.execute_reply.started":"2025-05-03T19:06:38.716678Z","shell.execute_reply":"2025-05-03T19:06:41.946494Z"}},"outputs":[{"name":"stdout","text":"Feedback segment stats:\nShape: torch.Size([32, 16, 261])\nMean: 0.0000, Std: 0.9996\nMin: -3.4627, Max: 4.3991\nLabel ratio: 75.00% positive\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"class EEGSimpleModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv1d(16, 32, kernel_size=5, padding=2),  # Temporal convolution\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.MaxPool1d(2)\n        )\n        self.rnn = nn.GRU(32, 16, batch_first=True)  # Reduced complexity\n        self.head = nn.Linear(16, 1)\n        \n    def forward(self, x):\n        x = self.conv(x)  # (batch, 32, seq_len//2)\n        x = x.permute(0, 2, 1)  # (batch, seq_len//2, 32)\n        _, h = self.rnn(x)\n        return torch.sigmoid(self.head(h.squeeze(0)))\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nmodel = EEGSimpleModel().to(device)\n# Replace BCELoss with more stable version\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3850/1590]).to(device))  # 2.42:1 weighting\n\n# Add gradient clipping (critical for RNNs)\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)  # Lower LR\n\nNUM_EPOCHS = 15\nMODEL_PATH = '/kaggle/working/best_model_try3.pth'\n# Add warmup and better scheduling\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=1e-4,\n    steps_per_epoch=len(train_loader),\n    epochs=NUM_EPOCHS,\n    pct_start=0.3\n)\n\n# Early stopping with memory\nbest_auc = 0\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    for batch in train_loader:\n        inputs = batch[2].to(device)  # Feedback segment\n        labels = batch[3].to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs.squeeze(), labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n    \n    val_auc = validate(model, val_loader)\n    print(f\"Epoch {epoch+1}: Loss={loss.item():.4f}, Val AUC={val_auc:.4f}\")\n    \n    if val_auc > best_auc + 0.005:\n        best_auc = val_auc\n        torch.save(model.state_dict(), MODEL_PATH)\n    elif epoch > 4 and val_auc < 0.55:\n        print(\"Stopping - no improvement\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:13:46.897274Z","iopub.execute_input":"2025-05-03T19:13:46.898139Z","iopub.status.idle":"2025-05-03T19:25:52.812150Z","shell.execute_reply.started":"2025-05-03T19:13:46.898110Z","shell.execute_reply":"2025-05-03T19:25:52.811166Z"}},"outputs":[{"name":"stdout","text":"cuda\nEpoch 1: Loss=1.0721, Val AUC=0.5109\nEpoch 2: Loss=1.0364, Val AUC=0.4953\nEpoch 3: Loss=1.0217, Val AUC=0.4935\nEpoch 4: Loss=0.9727, Val AUC=0.4965\nEpoch 5: Loss=0.9246, Val AUC=0.4930\nEpoch 6: Loss=0.9176, Val AUC=0.4974\nStopping - no improvement\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"class P300Detector(nn.Module):\n    def __init__(self, n_channels=16):\n        super().__init__()\n        # Spatial attention (channel importance)\n        self.spatial_att = nn.Sequential(\n            nn.Conv1d(n_channels, 32, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv1d(32, n_channels, kernel_size=1),\n            nn.Sigmoid()\n        )\n        \n        # Temporal convolution (P300 typically 250-500ms)\n        self.temp_conv = nn.Sequential(\n            nn.Conv1d(n_channels, 64, kernel_size=int(0.3*200)),  # 300ms window @200Hz\n            nn.BatchNorm1d(64),\n            nn.ELU(),\n            nn.MaxPool1d(4)\n        )\n        \n        # LSTM for temporal context\n        self.lstm = nn.LSTM(\n            input_size=64,\n            hidden_size=32,\n            bidirectional=True,\n            batch_first=True\n        )\n        \n        # Decision head\n        self.head = nn.Sequential(\n            nn.Linear(64, 16),\n            nn.ELU(),\n            nn.Dropout(0.3),\n            nn.Linear(16, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # x shape: (batch, channels, time)\n        \n        # Spatial attention\n        att_weights = self.spatial_att(x)  # (batch, channels, 1)\n        x = x * att_weights\n        \n        # Temporal processing\n        x = self.temp_conv(x)  # (batch, 64, time//4)\n        x = x.permute(0, 2, 1)  # (batch, time//4, 64)\n        \n        # Sequence modeling\n        lstm_out, _ = self.lstm(x)\n        x = lstm_out.mean(dim=1)  # (batch, 64)\n        \n        return self.head(x).squeeze(-1)\n\n# Custom loss function for ERPs\nclass P300Loss(nn.Module):\n    def __init__(self, pos_weight=2.42):  # 3850/1590 ratio\n        super().__init__()\n        self.pos_weight = pos_weight\n        \n    def forward(self, preds, targets):\n        loss = F.binary_cross_entropy(preds, targets, reduction='none')\n        # Emphasize 250-500ms window errors\n        if preds.dim() > 1:  # If using sequence outputs\n            time_weights = torch.linspace(1, 3, preds.shape[1]).to(preds.device)\n            loss = (loss * time_weights).mean()\n        return loss.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:32:39.185579Z","iopub.execute_input":"2025-05-03T19:32:39.186244Z","iopub.status.idle":"2025-05-03T19:32:39.194420Z","shell.execute_reply.started":"2025-05-03T19:32:39.186219Z","shell.execute_reply":"2025-05-03T19:32:39.193494Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Initialize\nmodel = P300Detector(n_channels=16).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)\ncriterion = P300Loss(pos_weight=3850/1590)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:55:24.617427Z","iopub.execute_input":"2025-05-03T19:55:24.617717Z","iopub.status.idle":"2025-05-03T19:55:24.627813Z","shell.execute_reply.started":"2025-05-03T19:55:24.617693Z","shell.execute_reply":"2025-05-03T19:55:24.627257Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"def validate(model, val_loader):\n    \"\"\"Compute validation AUC-ROC score\"\"\"\n    model.eval()  # Set to evaluation mode\n    all_probs = []\n    all_labels = []\n    \n    with torch.no_grad():  # Disable gradient calculation\n        for batch in val_loader:\n            # Assuming batch contains (green, blink, feedback, labels)\n            inputs = batch[2].to(device)  # Using feedback segment\n            labels = batch[3].cpu().numpy()  # Keep on CPU\n            \n            # Get model predictions\n            outputs = model(inputs)\n            probs = torch.sigmoid(outputs).cpu().numpy()  # Convert to probabilities\n            \n            all_probs.extend(probs)\n            all_labels.extend(labels)\n    \n    # Handle edge case where validation set has only one class\n    if len(np.unique(all_labels)) == 1:\n        print(\"Warning: Validation set contains only one class!\")\n        return 0.5  # Neutral AUC score\n    \n    return roc_auc_score(all_labels, all_probs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:55:33.634123Z","iopub.execute_input":"2025-05-03T19:55:33.634419Z","iopub.status.idle":"2025-05-03T19:55:33.640029Z","shell.execute_reply.started":"2025-05-03T19:55:33.634396Z","shell.execute_reply":"2025-05-03T19:55:33.639279Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Freeze all except temporal layers\nfor name, param in model.named_parameters():\n    if 'temp_conv' not in name:\n        param.requires_grad = False\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\nbest_auc = 0.5\n\nfor epoch in range(5):\n    model.train()\n    for _, _, inputs, labels in train_loader:  # Assuming you've modified loader to return (feedback, labels)\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n    \n    # Validation\n    model.eval()\n    val_probs, val_labels = [], []\n    with torch.no_grad():\n        for _, _, inputs, labels in val_loader:\n            outputs = model(inputs.to(device)).sigmoid().cpu()\n            val_probs.extend(outputs.numpy())\n            val_labels.extend(labels.numpy())\n    \n    val_auc = roc_auc_score(val_labels, val_probs)\n    print(f\"Phase1 Epoch {epoch+1}: Val AUC={val_auc:.4f}\")\n    \n    # Save best model\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), '/kaggle/working/best_phase1.pth')\n        print(f\"↳ New best model saved (AUC={val_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:56:08.995460Z","iopub.execute_input":"2025-05-03T19:56:08.995746Z","iopub.status.idle":"2025-05-03T20:06:21.253416Z","shell.execute_reply.started":"2025-05-03T19:56:08.995724Z","shell.execute_reply":"2025-05-03T20:06:21.252396Z"}},"outputs":[{"name":"stdout","text":"Phase1 Epoch 1: Val AUC=0.5410\n↳ New best model saved (AUC=0.5410)\nPhase1 Epoch 2: Val AUC=0.5655\n↳ New best model saved (AUC=0.5655)\nPhase1 Epoch 3: Val AUC=0.5680\n↳ New best model saved (AUC=0.5680)\nPhase1 Epoch 4: Val AUC=0.5765\n↳ New best model saved (AUC=0.5765)\nPhase1 Epoch 5: Val AUC=0.5791\n↳ New best model saved (AUC=0.5791)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# Unfreeze all layers\nfor param in model.parameters():\n    param.requires_grad = True\n\n# Load best phase1 weights\nmodel.load_state_dict(torch.load('/kaggle/working/best_phase1.pth'))\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\nbest_auc = 0\n\nfor epoch in range(10):\n    model.train()\n    epoch_loss = 0\n    for _, _, inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        epoch_loss += loss.item()\n    \n    # Validation\n    val_auc = validate(model, val_loader)  # Your existing validate function\n    scheduler.step(val_auc)\n    \n    print(f\"Phase2 Epoch {epoch+1}: Loss={epoch_loss/len(train_loader):.4f}, Val AUC={val_auc:.4f}\")\n    \n    # Save best model\n    if val_auc > best_auc + 0.001:  # Minimum improvement threshold\n        best_auc = val_auc\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_auc': val_auc,\n        }, '/kaggle/working/best_phase2.pth')\n        print(f\"↳ New best model saved (AUC={val_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:06:55.701528Z","iopub.execute_input":"2025-05-03T20:06:55.701847Z","iopub.status.idle":"2025-05-03T20:26:41.921736Z","shell.execute_reply.started":"2025-05-03T20:06:55.701822Z","shell.execute_reply":"2025-05-03T20:26:41.920925Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1374134449.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/best_phase1.pth'))\n","output_type":"stream"},{"name":"stdout","text":"Phase2 Epoch 1: Loss=0.6147, Val AUC=0.5865\n↳ New best model saved (AUC=0.5865)\nPhase2 Epoch 2: Loss=0.6029, Val AUC=0.5967\n↳ New best model saved (AUC=0.5967)\nPhase2 Epoch 3: Loss=0.5976, Val AUC=0.5953\nPhase2 Epoch 4: Loss=0.5987, Val AUC=0.6005\n↳ New best model saved (AUC=0.6005)\nPhase2 Epoch 5: Loss=0.5939, Val AUC=0.6037\n↳ New best model saved (AUC=0.6037)\nPhase2 Epoch 6: Loss=0.5944, Val AUC=0.6127\n↳ New best model saved (AUC=0.6127)\nPhase2 Epoch 7: Loss=0.5926, Val AUC=0.6082\nPhase2 Epoch 8: Loss=0.5882, Val AUC=0.6164\n↳ New best model saved (AUC=0.6164)\nPhase2 Epoch 9: Loss=0.5888, Val AUC=0.6178\n↳ New best model saved (AUC=0.6178)\nPhase2 Epoch 10: Loss=0.5846, Val AUC=0.6190\n↳ New best model saved (AUC=0.6190)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"# Load best phase2 checkpoint\ncheckpoint = torch.load('/kaggle/working/best_phase2.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n# Smaller LR for fine-tuning\nfor g in optimizer.param_groups:\n    g['lr'] = 1e-5\n\nbest_auc = checkpoint['val_auc']\n\nfor epoch in range(5):\n    model.train()\n    for _, _, inputs, labels in train_loader:\n        # Focus on P300 window (250-600ms @200Hz = 50:120 samples)\n        inputs = inputs[:, :, 50:120].to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    val_auc = validate(model, val_loader)\n    print(f\"Phase3 Epoch {epoch+1}: Val AUC={val_auc:.4f}\")\n    \n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), '/kaggle/working/best_model_try4.pth')\n        print(f\"↳ New best model saved (AUC={val_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:28:40.251460Z","iopub.execute_input":"2025-05-03T20:28:40.251792Z","iopub.status.idle":"2025-05-03T20:38:23.892029Z","shell.execute_reply.started":"2025-05-03T20:28:40.251765Z","shell.execute_reply":"2025-05-03T20:38:23.890975Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1064937418.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load('/kaggle/working/best_phase2.pth')\n","output_type":"stream"},{"name":"stdout","text":"Phase3 Epoch 1: Val AUC=0.6199\n↳ New best model saved (AUC=0.6199)\nPhase3 Epoch 2: Val AUC=0.6155\nPhase3 Epoch 3: Val AUC=0.6128\nPhase3 Epoch 4: Val AUC=0.6116\nPhase3 Epoch 5: Val AUC=0.6097\n","output_type":"stream"}],"execution_count":59}]}