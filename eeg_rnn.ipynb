{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11676112,"sourceType":"datasetVersion","datasetId":7313426}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport h5py\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:49:30.874908Z","iopub.execute_input":"2025-05-04T17:49:30.875208Z","iopub.status.idle":"2025-05-04T17:49:30.879525Z","shell.execute_reply.started":"2025-05-04T17:49:30.875188Z","shell.execute_reply":"2025-05-04T17:49:30.878911Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nRAND_STATE = 42\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\nset_seed(RAND_STATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:45:15.749676Z","iopub.execute_input":"2025-05-04T17:45:15.750390Z","iopub.status.idle":"2025-05-04T17:45:15.849136Z","shell.execute_reply.started":"2025-05-04T17:45:15.750363Z","shell.execute_reply":"2025-05-04T17:45:15.848373Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"labels_df = pd.read_csv('/kaggle/input/bci-rnn-raw-data/TrainLabels.csv')\nlabels = labels_df['Prediction'].to_numpy()\nprint(labels.shape, len(labels))\nlabel_stats = np.unique(labels, return_counts=True)\nprint(label_stats)\nprint(label_stats[1][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:47:52.481818Z","iopub.execute_input":"2025-05-04T17:47:52.482097Z","iopub.status.idle":"2025-05-04T17:47:52.493402Z","shell.execute_reply.started":"2025-05-04T17:47:52.482079Z","shell.execute_reply":"2025-05-04T17:47:52.492715Z"}},"outputs":[{"name":"stdout","text":"(5440,) 5440\n(array([0, 1]), array([1590, 3850]))\n1590\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"TRAIN_DATA_PATH = '/kaggle/input/bci-rnn-raw-data/rnn_data/rnn_data/eeg_train_data.h5'\n\nclass EEGDataset(Dataset):\n    def __init__(self, path, labels, segment_names=['green', 'blinking', 'feedback']):\n        self.path = path\n        self.labels = labels\n        self.segment_names = segment_names\n        \n        # Verify data consistency on initialization\n        with h5py.File(path, 'r') as f:\n            self.num_trials = len(f[segment_names[0]])  # All groups should have same length\n            for name in segment_names:\n                assert len(f[name]) == self.num_trials, f\"Mismatched trial counts in {name} group\"\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        with h5py.File(self.path, 'r') as f:\n            segments = []\n            for name in self.segment_names:\n                seg_data = f[name][str(idx)][:]  \n                seg_data = np.squeeze(seg_data) # remove if there's a dim of 1\n\n                # Ensure shape is (n_channels, n_samples)\n                if seg_data.ndim == 1:\n                    seg_data = seg_data[np.newaxis, :]  # If single channel\n                \n                seg_data = (seg_data - np.mean(seg_data, axis=1, keepdims=True)) / (np.std(seg_data, axis=1, keepdims=True) + 1e-6)  # Avoid division by zero\n                \n                segments.append(torch.FloatTensor(seg_data))\n            \n            label = torch.tensor(self.labels[idx], dtype=torch.float32)\n            # Assuming you'll add labels later\n            return (*segments, label)  # (green_tensor, blinking_tensor, feedback_tensor, label_tensor)\n\ndef collate_fn(batch):\n    \"\"\"Handles variable-length segments and labels\"\"\"\n    \n    # Verify and correct shapes before processing\n    processed_batch = []\n    for item in batch:\n        # Ensure each segment has shape (n_channels, n_samples)\n        corrected_item = []\n        for seg in item[:3]:  # For each of the 3 segments\n            if seg.dim() == 3:\n                seg = seg.squeeze(0)  # Remove batch dimension if present\n            corrected_item.append(seg)\n        corrected_item.append(item[3])  # Keep label unchanged\n        processed_batch.append(tuple(corrected_item))\n    \n    # Now process with corrected shapes\n    green_segs = [item[0].permute(1, 0) for item in processed_batch]\n    blink_segs = [item[1].permute(1, 0) for item in processed_batch]\n    feedback_segs = [item[2].permute(1, 0) for item in processed_batch]\n    labels = torch.stack([item[3] for item in processed_batch])\n    \n    # Pad each segment type\n    green_padded = pad_sequence(green_segs, batch_first=True).permute(0, 2, 1)\n    blink_padded = pad_sequence(blink_segs, batch_first=True).permute(0, 2, 1)\n    feedback_padded = pad_sequence(feedback_segs, batch_first=True).permute(0, 2, 1)\n    \n    return green_padded, blink_padded, feedback_padded, labels\n\ndataset = EEGDataset(TRAIN_DATA_PATH, labels)\ndataloader = DataLoader(\n    dataset,\n    batch_size=32,\n    collate_fn=collate_fn,\n    shuffle=True#,\n    #num_workers=2  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:45:20.480164Z","iopub.execute_input":"2025-05-04T17:45:20.480452Z","iopub.status.idle":"2025-05-04T17:45:24.928824Z","shell.execute_reply.started":"2025-05-04T17:45:20.480433Z","shell.execute_reply":"2025-05-04T17:45:24.928163Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"len(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T12:57:03.164047Z","iopub.execute_input":"2025-05-04T12:57:03.164717Z","iopub.status.idle":"2025-05-04T12:57:03.169800Z","shell.execute_reply.started":"2025-05-04T12:57:03.164693Z","shell.execute_reply":"2025-05-04T12:57:03.169165Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"5440"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"dataset[8][2].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T12:57:05.689355Z","iopub.execute_input":"2025-05-04T12:57:05.689946Z","iopub.status.idle":"2025-05-04T12:57:05.784264Z","shell.execute_reply.started":"2025-05-04T12:57:05.689922Z","shell.execute_reply":"2025-05-04T12:57:05.783644Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 261])"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Split indices (stratified by labels)\ntrain_idx, val_idx = train_test_split(\n    range(len(dataset)),\n    test_size=0.2,\n    stratify=labels,  # Important for imbalanced classes\n    random_state=42\n)\n\ntrain_loader = DataLoader(\n    Subset(dataset, train_idx),\n    batch_size=32,\n    shuffle=True,\n    collate_fn=collate_fn#,\n    #num_workers=2\n)\n\nval_loader = DataLoader(\n    Subset(dataset, val_idx),\n    batch_size=32,\n    shuffle=False,\n    collate_fn=collate_fn#,\n    #num_workers=2\n)\n\n# 4. Verify\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:45:30.240813Z","iopub.execute_input":"2025-05-04T17:45:30.241100Z","iopub.status.idle":"2025-05-04T17:45:30.254177Z","shell.execute_reply.started":"2025-05-04T17:45:30.241078Z","shell.execute_reply":"2025-05-04T17:45:30.253604Z"}},"outputs":[{"name":"stdout","text":"Train batches: 136\nVal batches: 34\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"hand_train = np.load(\"/kaggle/input/bci-rnn-raw-data/handcrafted_features_train.npy\")\nhand_test = np.load(\"/kaggle/input/bci-rnn-raw-data/handcrafted_features_test.npy\")\nprint(hand_train.shape, hand_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:45:32.824111Z","iopub.execute_input":"2025-05-04T17:45:32.824397Z","iopub.status.idle":"2025-05-04T17:45:32.853041Z","shell.execute_reply.started":"2025-05-04T17:45:32.824378Z","shell.execute_reply":"2025-05-04T17:45:32.852220Z"}},"outputs":[{"name":"stdout","text":"(5440, 28) (3400, 28)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"class EEGRNN(nn.Module):\n    # input_dim = number of channels\n    def __init__(self, input_dim=16, hidden_dim=64, num_layers=2, dropout=0.3):\n        super().__init__()\n        self.rnn = nn.GRU(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            bidirectional=True,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim*2, 32),  # *2 for bidirectional\n            nn.ReLU(),\n            nn.Linear(32, 1),\n            nn.Sigmoid()  # Output probabilities\n        )\n\n    def forward(self, x, lengths=None):\n        # x shape: (batch, channels, seq_len)\n        x = x.permute(0, 2, 1)  # (batch, seq_len, channels)\n        \n        if lengths is not None:\n            # Pack padded sequences if lengths are provided\n            x = nn.utils.rnn.pack_padded_sequence(\n                x, lengths.cpu(), batch_first=True, enforce_sorted=False\n            )\n        \n        _, hidden = self.rnn(x)  # hidden: (num_layers*2, batch, hidden_dim)\n        \n        # Concatenate last hidden states from both directions\n        hidden = hidden.view(self.rnn.num_layers, 2, -1, self.rnn.hidden_size)\n        last_hidden = torch.cat([hidden[-1, 0], hidden[-1, 1]], dim=1)\n        \n        return self.classifier(self.dropout(last_hidden)).squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:25:48.277904Z","iopub.execute_input":"2025-05-03T17:25:48.278176Z","iopub.status.idle":"2025-05-03T17:25:48.284781Z","shell.execute_reply.started":"2025-05-03T17:25:48.278158Z","shell.execute_reply":"2025-05-03T17:25:48.284195Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\nprint(device)\n\nmodel = EEGRNN(input_dim=16, hidden_dim=32, dropout=0.1).to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n\n#criterion = nn.BCELoss()  # Binary cross-entropy for probabilities\n# Calculate class weights\nclass_weights = torch.tensor([label_stats[1][1]/label_stats[1][0], 1.0], dtype=torch.float32).to(device)  # [2.42, 1.0]\n\n# Modify your loss function\ncriterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[0])  # Automatic weighting\n\n# Learning rate scheduler\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='max', factor=0.5, patience=3, verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:57:30.536392Z","iopub.execute_input":"2025-05-03T17:57:30.537118Z","iopub.status.idle":"2025-05-03T17:57:30.548045Z","shell.execute_reply.started":"2025-05-03T17:57:30.537092Z","shell.execute_reply":"2025-05-03T17:57:30.547287Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def train_epoch(model, loader):\n    model.train()\n    total_loss = 0\n    for green, blink, feedback, labels in loader:\n        # Use whichever segment type performs best (start with feedback)\n        inputs = feedback.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\ndef validate(model, loader):\n    model.eval()\n    all_probs = []\n    all_labels = []\n    with torch.no_grad():\n        for green, blink, feedback, labels in loader:\n            inputs = feedback.to(device)\n            outputs = model(inputs).cpu().numpy()\n            all_probs.extend(outputs)\n            all_labels.extend(labels.numpy())\n    return roc_auc_score(all_labels, all_probs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:57:33.768654Z","iopub.execute_input":"2025-05-03T17:57:33.768912Z","iopub.status.idle":"2025-05-03T17:57:33.774454Z","shell.execute_reply.started":"2025-05-03T17:57:33.768895Z","shell.execute_reply":"2025-05-03T17:57:33.773833Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"Try|Best Score|Loss\n:-:|:-:|:-:\n1|0.5686|0.6064\n2|0.5448|0.9794\n3|0.5109|1.0721\n4|0.6199|-\n5|0.6862|0.5448\n6|0.6879|0.2125","metadata":{}},{"cell_type":"code","source":"NUM_EPOCHS = 15\nMODEL_PATH = '/kaggle/working/best_model_try2.pth'\n\nbest_auc = 0\nfor epoch in range(NUM_EPOCHS):\n    train_loss = train_epoch(model, train_loader)\n    val_auc = validate(model, val_loader)\n    scheduler.step(val_auc)\n    \n    print(f\"Epoch {epoch+1}: Loss={train_loss:.4f}, Val AUC={val_auc:.4f}\")\n    \n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), MODEL_PATH)\n        print(\"↳ New best model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:14:59.726163Z","iopub.execute_input":"2025-05-03T18:14:59.726875Z","iopub.status.idle":"2025-05-03T18:46:41.806396Z","shell.execute_reply.started":"2025-05-03T18:14:59.726848Z","shell.execute_reply":"2025-05-03T18:46:41.805429Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Loss=0.9794, Val AUC=0.5448\n↳ New best model saved!\nEpoch 2: Loss=0.9286, Val AUC=0.5448\nEpoch 3: Loss=0.9229, Val AUC=0.5428\nEpoch 4: Loss=0.9217, Val AUC=0.5413\nEpoch 5: Loss=0.9213, Val AUC=0.5396\nEpoch 6: Loss=0.9211, Val AUC=0.5391\nEpoch 7: Loss=0.9211, Val AUC=0.5389\nEpoch 8: Loss=0.9210, Val AUC=0.5383\nEpoch 9: Loss=0.9209, Val AUC=0.5380\nEpoch 10: Loss=0.9209, Val AUC=0.5379\nEpoch 11: Loss=0.9209, Val AUC=0.5376\nEpoch 12: Loss=0.9209, Val AUC=0.5376\nEpoch 13: Loss=0.9209, Val AUC=0.5373\nEpoch 14: Loss=0.9208, Val AUC=0.5371\nEpoch 15: Loss=0.9208, Val AUC=0.5369\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"batch = next(iter(train_loader))\ngreen, blink, feedback, labels_t = batch\nprint(\"Feedback segment stats:\")\nprint(f\"Shape: {feedback.shape}\")\nprint(f\"Mean: {feedback.mean():.4f}, Std: {feedback.std():.4f}\")\nprint(f\"Min: {feedback.min():.4f}, Max: {feedback.max():.4f}\")\nprint(f\"Label ratio: {labels_t.sum()/len(labels_t):.2%} positive\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:06:38.716386Z","iopub.execute_input":"2025-05-03T19:06:38.716700Z","iopub.status.idle":"2025-05-03T19:06:41.947455Z","shell.execute_reply.started":"2025-05-03T19:06:38.716678Z","shell.execute_reply":"2025-05-03T19:06:41.946494Z"}},"outputs":[{"name":"stdout","text":"Feedback segment stats:\nShape: torch.Size([32, 16, 261])\nMean: 0.0000, Std: 0.9996\nMin: -3.4627, Max: 4.3991\nLabel ratio: 75.00% positive\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"class EEGSimpleModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv1d(16, 32, kernel_size=5, padding=2),  # Temporal convolution\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.MaxPool1d(2)\n        )\n        self.rnn = nn.GRU(32, 16, batch_first=True)  # Reduced complexity\n        self.head = nn.Linear(16, 1)\n        \n    def forward(self, x):\n        x = self.conv(x)  # (batch, 32, seq_len//2)\n        x = x.permute(0, 2, 1)  # (batch, seq_len//2, 32)\n        _, h = self.rnn(x)\n        return torch.sigmoid(self.head(h.squeeze(0)))\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nmodel = EEGSimpleModel().to(device)\n# Replace BCELoss with more stable version\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3850/1590]).to(device))  # 2.42:1 weighting\n\n# Add gradient clipping (critical for RNNs)\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)  # Lower LR\n\nNUM_EPOCHS = 15\nMODEL_PATH = '/kaggle/working/best_model_try3.pth'\n# Add warmup and better scheduling\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=1e-4,\n    steps_per_epoch=len(train_loader),\n    epochs=NUM_EPOCHS,\n    pct_start=0.3\n)\n\n# Early stopping with memory\nbest_auc = 0\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    for batch in train_loader:\n        inputs = batch[2].to(device)  # Feedback segment\n        labels = batch[3].to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs.squeeze(), labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n    \n    val_auc = validate(model, val_loader)\n    print(f\"Epoch {epoch+1}: Loss={loss.item():.4f}, Val AUC={val_auc:.4f}\")\n    \n    if val_auc > best_auc + 0.005:\n        best_auc = val_auc\n        torch.save(model.state_dict(), MODEL_PATH)\n    elif epoch > 4 and val_auc < 0.55:\n        print(\"Stopping - no improvement\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:13:46.897274Z","iopub.execute_input":"2025-05-03T19:13:46.898139Z","iopub.status.idle":"2025-05-03T19:25:52.812150Z","shell.execute_reply.started":"2025-05-03T19:13:46.898110Z","shell.execute_reply":"2025-05-03T19:25:52.811166Z"}},"outputs":[{"name":"stdout","text":"cuda\nEpoch 1: Loss=1.0721, Val AUC=0.5109\nEpoch 2: Loss=1.0364, Val AUC=0.4953\nEpoch 3: Loss=1.0217, Val AUC=0.4935\nEpoch 4: Loss=0.9727, Val AUC=0.4965\nEpoch 5: Loss=0.9246, Val AUC=0.4930\nEpoch 6: Loss=0.9176, Val AUC=0.4974\nStopping - no improvement\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"class P300Detector(nn.Module):\n    def __init__(self, n_channels=16):\n        super().__init__()\n        # Spatial attention (channel importance)\n        self.spatial_att = nn.Sequential(\n            nn.Conv1d(n_channels, 32, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv1d(32, n_channels, kernel_size=1),\n            nn.Sigmoid()\n        )\n        \n        # Temporal convolution (P300 typically 250-500ms)\n        self.temp_conv = nn.Sequential(\n            nn.Conv1d(n_channels, 64, kernel_size=int(0.3*200)),  # 300ms window @200Hz\n            nn.BatchNorm1d(64),\n            nn.ELU(),\n            nn.MaxPool1d(4)\n        )\n        \n        # LSTM for temporal context\n        self.lstm = nn.LSTM(\n            input_size=64,\n            hidden_size=32,\n            bidirectional=True,\n            batch_first=True\n        )\n        \n        # Decision head\n        self.head = nn.Sequential(\n            nn.Linear(64, 16),\n            nn.ELU(),\n            nn.Dropout(0.3),\n            nn.Linear(16, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # x shape: (batch, channels, time)\n        \n        # Spatial attention\n        att_weights = self.spatial_att(x)  # (batch, channels, 1)\n        x = x * att_weights\n        \n        # Temporal processing\n        x = self.temp_conv(x)  # (batch, 64, time//4)\n        x = x.permute(0, 2, 1)  # (batch, time//4, 64)\n        \n        # Sequence modeling\n        lstm_out, _ = self.lstm(x)\n        x = lstm_out.mean(dim=1)  # (batch, 64)\n        \n        return self.head(x).squeeze(-1), x # return the probabilities and the features\n\n# Custom loss function for ERPs\nclass P300Loss(nn.Module):\n    def __init__(self, pos_weight=2.42):  # 3850/1590 ratio\n        super().__init__()\n        self.pos_weight = pos_weight\n        \n    def forward(self, preds, targets):\n        loss = F.binary_cross_entropy(preds, targets, reduction='none')\n        # Emphasize 250-500ms window errors\n        if preds.dim() > 1:  # If using sequence outputs\n            time_weights = torch.linspace(1, 3, preds.shape[1]).to(preds.device)\n            loss = (loss * time_weights).mean()\n        return loss.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:46:34.529442Z","iopub.execute_input":"2025-05-04T17:46:34.529989Z","iopub.status.idle":"2025-05-04T17:46:34.539152Z","shell.execute_reply.started":"2025-05-04T17:46:34.529965Z","shell.execute_reply":"2025-05-04T17:46:34.538611Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Initialize\nmodel = P300Detector(n_channels=16).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)\ncriterion = P300Loss(pos_weight=3850/1590)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T12:13:39.078173Z","iopub.execute_input":"2025-05-04T12:13:39.078721Z","iopub.status.idle":"2025-05-04T12:13:39.087882Z","shell.execute_reply.started":"2025-05-04T12:13:39.078700Z","shell.execute_reply":"2025-05-04T12:13:39.087271Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"def validate(model, val_loader):\n    \"\"\"Compute validation AUC-ROC score\"\"\"\n    model.eval()  # Set to evaluation mode\n    all_probs = []\n    all_labels = []\n    \n    with torch.no_grad():  # Disable gradient calculation\n        for batch in val_loader:\n            # Assuming batch contains (green, blink, feedback, labels)\n            inputs = batch[2].to(device)  # Using feedback segment\n            labels = batch[3].cpu().numpy()  # Keep on CPU\n            \n            # Get model predictions\n            outputs, _ = model(inputs)\n            probs = torch.sigmoid(outputs).cpu().numpy()  # Convert to probabilities\n            \n            all_probs.extend(probs)\n            all_labels.extend(labels)\n    \n    # Handle edge case where validation set has only one class\n    if len(np.unique(all_labels)) == 1:\n        print(\"Warning: Validation set contains only one class!\")\n        return 0.5  # Neutral AUC score\n    \n    return roc_auc_score(all_labels, all_probs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:55:33.634123Z","iopub.execute_input":"2025-05-03T19:55:33.634419Z","iopub.status.idle":"2025-05-03T19:55:33.640029Z","shell.execute_reply.started":"2025-05-03T19:55:33.634396Z","shell.execute_reply":"2025-05-03T19:55:33.639279Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Freeze all except temporal layers\nfor name, param in model.named_parameters():\n    if 'temp_conv' not in name:\n        param.requires_grad = False\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\nbest_auc = 0.5\n\nfor epoch in range(5):\n    model.train()\n    for _, _, inputs, labels in train_loader:  # Assuming you've modified loader to return (feedback, labels)\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs, _ = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n    \n    # Validation\n    model.eval()\n    val_probs, val_labels = [], []\n    with torch.no_grad():\n        for _, _, inputs, labels in val_loader:\n            outputs, _ = model(inputs.to(device)).sigmoid().cpu()\n            val_probs.extend(outputs.numpy())\n            val_labels.extend(labels.numpy())\n    \n    val_auc = roc_auc_score(val_labels, val_probs)\n    print(f\"Phase1 Epoch {epoch+1}: Val AUC={val_auc:.4f}\")\n    \n    # Save best model\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), '/kaggle/working/best_phase1.pth')\n        print(f\"↳ New best model saved (AUC={val_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:56:08.995460Z","iopub.execute_input":"2025-05-03T19:56:08.995746Z","iopub.status.idle":"2025-05-03T20:06:21.253416Z","shell.execute_reply.started":"2025-05-03T19:56:08.995724Z","shell.execute_reply":"2025-05-03T20:06:21.252396Z"}},"outputs":[{"name":"stdout","text":"Phase1 Epoch 1: Val AUC=0.5410\n↳ New best model saved (AUC=0.5410)\nPhase1 Epoch 2: Val AUC=0.5655\n↳ New best model saved (AUC=0.5655)\nPhase1 Epoch 3: Val AUC=0.5680\n↳ New best model saved (AUC=0.5680)\nPhase1 Epoch 4: Val AUC=0.5765\n↳ New best model saved (AUC=0.5765)\nPhase1 Epoch 5: Val AUC=0.5791\n↳ New best model saved (AUC=0.5791)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# Unfreeze all layers\nfor param in model.parameters():\n    param.requires_grad = True\n\n# Load best phase1 weights\nmodel.load_state_dict(torch.load('/kaggle/working/best_phase1.pth'))\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\nbest_auc = 0\n\nfor epoch in range(10):\n    model.train()\n    epoch_loss = 0\n    for _, _, inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs, _ = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        epoch_loss += loss.item()\n    \n    # Validation\n    val_auc = validate(model, val_loader)  # Your existing validate function\n    scheduler.step(val_auc)\n    \n    print(f\"Phase2 Epoch {epoch+1}: Loss={epoch_loss/len(train_loader):.4f}, Val AUC={val_auc:.4f}\")\n    \n    # Save best model\n    if val_auc > best_auc + 0.001:  # Minimum improvement threshold\n        best_auc = val_auc\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_auc': val_auc,\n        }, '/kaggle/working/best_phase2.pth')\n        print(f\"↳ New best model saved (AUC={val_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:06:55.701528Z","iopub.execute_input":"2025-05-03T20:06:55.701847Z","iopub.status.idle":"2025-05-03T20:26:41.921736Z","shell.execute_reply.started":"2025-05-03T20:06:55.701822Z","shell.execute_reply":"2025-05-03T20:26:41.920925Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1374134449.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/best_phase1.pth'))\n","output_type":"stream"},{"name":"stdout","text":"Phase2 Epoch 1: Loss=0.6147, Val AUC=0.5865\n↳ New best model saved (AUC=0.5865)\nPhase2 Epoch 2: Loss=0.6029, Val AUC=0.5967\n↳ New best model saved (AUC=0.5967)\nPhase2 Epoch 3: Loss=0.5976, Val AUC=0.5953\nPhase2 Epoch 4: Loss=0.5987, Val AUC=0.6005\n↳ New best model saved (AUC=0.6005)\nPhase2 Epoch 5: Loss=0.5939, Val AUC=0.6037\n↳ New best model saved (AUC=0.6037)\nPhase2 Epoch 6: Loss=0.5944, Val AUC=0.6127\n↳ New best model saved (AUC=0.6127)\nPhase2 Epoch 7: Loss=0.5926, Val AUC=0.6082\nPhase2 Epoch 8: Loss=0.5882, Val AUC=0.6164\n↳ New best model saved (AUC=0.6164)\nPhase2 Epoch 9: Loss=0.5888, Val AUC=0.6178\n↳ New best model saved (AUC=0.6178)\nPhase2 Epoch 10: Loss=0.5846, Val AUC=0.6190\n↳ New best model saved (AUC=0.6190)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"# Load best phase2 checkpoint\ncheckpoint = torch.load('/kaggle/working/best_phase2.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n# Smaller LR for fine-tuning\nfor g in optimizer.param_groups:\n    g['lr'] = 1e-5\n\nbest_auc = checkpoint['val_auc']\n\nfor epoch in range(5):\n    model.train()\n    for _, _, inputs, labels in train_loader:\n        # Focus on P300 window (250-600ms @200Hz = 50:120 samples)\n        inputs = inputs[:, :, 50:120].to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs, _ = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    val_auc = validate(model, val_loader)\n    print(f\"Phase3 Epoch {epoch+1}: Val AUC={val_auc:.4f}\")\n    \n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), '/kaggle/working/best_model_try4.pth')\n        print(f\"↳ New best model saved (AUC={val_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T20:28:40.251460Z","iopub.execute_input":"2025-05-03T20:28:40.251792Z","iopub.status.idle":"2025-05-03T20:38:23.892029Z","shell.execute_reply.started":"2025-05-03T20:28:40.251765Z","shell.execute_reply":"2025-05-03T20:38:23.890975Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1064937418.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load('/kaggle/working/best_phase2.pth')\n","output_type":"stream"},{"name":"stdout","text":"Phase3 Epoch 1: Val AUC=0.6199\n↳ New best model saved (AUC=0.6199)\nPhase3 Epoch 2: Val AUC=0.6155\nPhase3 Epoch 3: Val AUC=0.6128\nPhase3 Epoch 4: Val AUC=0.6116\nPhase3 Epoch 5: Val AUC=0.6097\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"class EnhancedDataset(Dataset):\n    def __init__(self, path, hand_features, labels):\n        self.eeg_dataset = EEGDataset(path, labels)  # Existing simple dataset\n        self.features = torch.FloatTensor(hand_features)\n        self.labels = torch.FloatTensor(labels)\n\n        print(len(self.eeg_dataset), len(self.features), len(self.labels))\n        assert len(self.eeg_dataset) == len(self.features) == len(self.labels)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        # Get EEG segments\n        green, blink, feedback = self.eeg_dataset[idx][:3]\n        \n        # Get handcrafted features\n        session = self.features[idx, 0].long()  # int\n        trial = self.features[idx, 1].long()    # int\n        is_short = self.features[idx, 2]        # float (0.0 or 1.0)\n        similarities = self.features[idx, 3:]   # (25,)\n        \n        return (green, blink, feedback, \n                session, trial, is_short, similarities, \n                self.labels[idx])\n\ndef enhanced_collate_fn(batch):\n    processed_batch = []\n\n    # item is a tuple: (green, blink, feedback, session, trial, is_short, similarities, label)\n    for item in batch:\n        # Ensure each segment has shape (n_channels, n_samples)\n        corrected_item = []\n        for seg in item[:3]:  # For each of the 3 segments\n            if seg.dim() == 3:\n                seg = seg.squeeze(0)  # Remove batch dimension if present\n            corrected_item.append(seg)\n\n        for item_i in range(3, 8): # keep the rest of the tuple as is\n            corrected_item.append(item[item_i])\n        \n        processed_batch.append(tuple(corrected_item))\n    \n    green_segs = [item[0].permute(1, 0) for item in processed_batch]\n    blink_segs = [item[1].permute(1, 0) for item in processed_batch]\n    feedback_segs = [item[2].permute(1, 0) for item in processed_batch]\n    session = torch.stack([item[3] for item in processed_batch])\n    trial = torch.stack([item[4] for item in processed_batch])\n    is_short = torch.stack([item[5] for item in processed_batch])\n    similarities = torch.stack([item[6] for item in processed_batch])\n    labels = torch.stack([item[7] for item in processed_batch])\n    \n    green_padded = pad_sequence(green_segs, batch_first=True).permute(0, 2, 1)\n    blink_padded = pad_sequence(blink_segs, batch_first=True).permute(0, 2, 1)\n    feedback_padded = pad_sequence(feedback_segs, batch_first=True).permute(0, 2, 1)\n    \n    return (green_padded, blink_padded, feedback_padded, session, trial, is_short, similarities, labels)\n\nclass FeatureProcessor(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # Meta-feature embeddings with dropout\n        self.session_embed = nn.Sequential(\n            nn.Embedding(100, 2),  \n            nn.BatchNorm1d(2),\n            nn.Dropout(0.1)\n        )\n        \n        self.trial_embed = nn.Sequential(\n            nn.Embedding(400, 2),  \n            nn.BatchNorm1d(2),\n            nn.Dropout(0.1)\n        )\n        \n        # Short-blink processor (binary → 16D)\n        self.short_blink_net = nn.Sequential(\n            nn.Linear(1, 16),\n            nn.BatchNorm1d(16),\n            nn.ELU(),\n            nn.Dropout(0.2)\n        )\n        \n        # Similarity metrics processor (25D → 32D → 16D)\n        self.similarity_net = nn.Sequential(\n            nn.Linear(25, 32),\n            nn.BatchNorm1d(32),\n            nn.ELU(),\n            nn.Dropout(0.3),\n            nn.Linear(32, 16),\n            nn.BatchNorm1d(16),\n            nn.ELU()\n        )\n\n    def forward(self, session, trial, is_short, similarities):\n        # Normalize similarity metrics (critical!)\n        similarities = (similarities - similarities.mean(dim=1, keepdim=True)) / (similarities.std(dim=1, keepdim=True) + 1e-6)\n        \n        session_emb = self.session_embed(session)  # (batch, 2)\n        trial_emb = self.trial_embed(trial)       # (batch, 2)\n        short_feat = self.short_blink_net(is_short.unsqueeze(1))  # (batch, 16)\n        sim_feat = self.similarity_net(similarities)  # (batch, 16)\n        \n        return torch.cat([session_emb, trial_emb, short_feat, sim_feat], dim=1)  # (batch, 36)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:46:46.603803Z","iopub.execute_input":"2025-05-04T17:46:46.604327Z","iopub.status.idle":"2025-05-04T17:46:46.617965Z","shell.execute_reply.started":"2025-05-04T17:46:46.604303Z","shell.execute_reply":"2025-05-04T17:46:46.617181Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class NickNet(nn.Module):\n    def __init__(self, pretrained_eeg_net):\n        super().__init__()\n        self.eeg_net = pretrained_eeg_net\n        self.freeze_eeg_net(True)\n        \n        self.feature_processor = FeatureProcessor()\n        \n        # More sophisticated fusion\n        self.fusion = nn.Sequential(\n            nn.Linear(64 + 36, 64),\n            nn.BatchNorm1d(64),\n            nn.ELU(),\n            nn.Dropout(0.3)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(64, 32),\n            nn.BatchNorm1d(32),\n            nn.ELU(),\n            nn.Dropout(0.3),\n            nn.Linear(32, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, eeg, session, trial, is_short, similarities):\n        _, eeg_feat = self.eeg_net(eeg)\n        features = self.feature_processor(session, trial, is_short, similarities)\n        \n        # Concatenate and fuse\n        combined = torch.cat([eeg_feat, features], dim=1)\n        fused = self.fusion(combined)\n        \n        return self.classifier(fused).squeeze(1)\n\n    def freeze_eeg_net(self, f: bool):\n        for param in self.eeg_net.parameters():\n            param.requires_grad = f","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:46:53.717309Z","iopub.execute_input":"2025-05-04T17:46:53.717910Z","iopub.status.idle":"2025-05-04T17:46:53.723818Z","shell.execute_reply.started":"2025-05-04T17:46:53.717886Z","shell.execute_reply":"2025-05-04T17:46:53.722932Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def validate(model, loader):\n    model.eval()\n    all_probs, all_labels = [], []\n    \n    with torch.no_grad():\n        for batch in loader:\n            _, _, feedback, session, trial, is_short, sim, labels = batch\n            inputs = feedback.to(device)\n            session = session.to(device)\n            trial = trial.to(device)\n            is_short = is_short.to(device)\n            sim = sim.to(device)\n            \n            outputs = model(inputs, session, trial, is_short, sim)\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            all_probs.extend(probs)\n            all_labels.extend(labels.cpu().numpy())\n    \n    return roc_auc_score(all_labels, all_probs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:46:57.596078Z","iopub.execute_input":"2025-05-04T17:46:57.596335Z","iopub.status.idle":"2025-05-04T17:46:57.601580Z","shell.execute_reply.started":"2025-05-04T17:46:57.596317Z","shell.execute_reply":"2025-05-04T17:46:57.600788Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"pretrained_eeg = P300Detector().to(device)\npretrained_eeg.load_state_dict(torch.load('/kaggle/input/bci-rnn-raw-data/best_model_try4.pth'))\nmodel = NickNet(pretrained_eeg).to(device)\n\n# Optimizer (only train new layers)\noptimizer = torch.optim.AdamW(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=1e-3,\n    weight_decay=1e-4\n)\n\n# Loss function with class weighting\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3850/1590]).to(device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:56:45.188030Z","iopub.execute_input":"2025-05-04T13:56:45.188551Z","iopub.status.idle":"2025-05-04T13:56:45.209507Z","shell.execute_reply.started":"2025-05-04T13:56:45.188528Z","shell.execute_reply":"2025-05-04T13:56:45.208911Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2026321379.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  pretrained_eeg.load_state_dict(torch.load('/kaggle/input/bci-rnn-raw-data/best_model_try4.pth'))\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"train_dataset = EnhancedDataset(TRAIN_DATA_PATH, hand_train, labels)\ntrain_idx, val_idx = train_test_split(\n    range(len(train_dataset)),\n    test_size=0.2,\n    stratify=labels,  # Important for imbalanced classes\n    random_state=RAND_STATE\n)\n\ntrain_loader = DataLoader(\n    Subset(train_dataset, train_idx),\n    batch_size=32,\n    shuffle=True,\n    collate_fn=enhanced_collate_fn\n    #num_workers=2\n)\n\nval_loader = DataLoader(\n    Subset(train_dataset, val_idx),\n    batch_size=32,\n    shuffle=False,\n    collate_fn=enhanced_collate_fn\n    #num_workers=2\n)\n\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:47:09.526270Z","iopub.execute_input":"2025-05-04T17:47:09.526566Z","iopub.status.idle":"2025-05-04T17:47:13.836986Z","shell.execute_reply.started":"2025-05-04T17:47:09.526518Z","shell.execute_reply":"2025-05-04T17:47:13.836005Z"}},"outputs":[{"name":"stdout","text":"5440 5440 5440\nTrain batches: 136\nVal batches: 34\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Compute weights for each sample\nds = Subset(train_dataset, train_idx)\nweights = [1.0 if label == 0 else label_stats[1][0]/label_stats[1][1] for _, _, _, _, _, _, _, label in ds]\nsampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n\n# Replace original train_loader\nbalanced_loader = DataLoader(\n    ds,\n    batch_size=32,\n    sampler=sampler,  # Overrides shuffle=True\n    collate_fn=enhanced_collate_fn\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:51:31.082269Z","iopub.execute_input":"2025-05-04T17:51:31.082599Z","iopub.status.idle":"2025-05-04T17:53:57.381637Z","shell.execute_reply.started":"2025-05-04T17:51:31.082572Z","shell.execute_reply":"2025-05-04T17:53:57.380790Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(len(balanced_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:55:04.305794Z","iopub.execute_input":"2025-05-04T17:55:04.306064Z","iopub.status.idle":"2025-05-04T17:55:04.310518Z","shell.execute_reply.started":"2025-05-04T17:55:04.306045Z","shell.execute_reply":"2025-05-04T17:55:04.309958Z"}},"outputs":[{"name":"stdout","text":"136\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(hand_train[:, 1]) # trial","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T12:01:56.893697Z","iopub.execute_input":"2025-05-04T12:01:56.893978Z","iopub.status.idle":"2025-05-04T12:01:56.898621Z","shell.execute_reply.started":"2025-05-04T12:01:56.893958Z","shell.execute_reply":"2025-05-04T12:01:56.897845Z"}},"outputs":[{"name":"stdout","text":"[  1.   2.   3. ...  98.  99. 100.]\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"t = next(iter(train_loader)) # a batch of size 32\nprint(len(t))\nprint(t[3], t[4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:52:11.642295Z","iopub.execute_input":"2025-05-04T11:52:11.642911Z","iopub.status.idle":"2025-05-04T11:52:15.287478Z","shell.execute_reply.started":"2025-05-04T11:52:11.642883Z","shell.execute_reply":"2025-05-04T11:52:15.286546Z"}},"outputs":[{"name":"stdout","text":"8\n[tensor(2), tensor(4), tensor(3), tensor(1), tensor(5), tensor(5), tensor(3), tensor(3), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(1), tensor(3), tensor(1), tensor(5), tensor(3), tensor(3), tensor(4), tensor(2), tensor(5), tensor(5), tensor(4), tensor(4), tensor(4), tensor(3), tensor(3), tensor(4), tensor(3), tensor(4), tensor(4)] [tensor(33), tensor(8), tensor(31), tensor(41), tensor(10), tensor(88), tensor(11), tensor(23), tensor(27), tensor(37), tensor(42), tensor(54), tensor(19), tensor(9), tensor(25), tensor(49), tensor(46), tensor(27), tensor(51), tensor(44), tensor(28), tensor(33), tensor(38), tensor(60), tensor(60), tensor(41), tensor(17), tensor(52), tensor(58), tensor(37), tensor(43), tensor(24)]\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"best_auc = 0.0\nfor epoch in range(15):\n    model.train()\n    for batch in train_loader:\n        _, _, feedback, session, trial, is_short, sim, labels = batch\n        inputs = feedback.to(device)\n        session = session.to(device)\n        trial = trial.to(device)\n        is_short = is_short.to(device)\n        sim = sim.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs, session, trial, is_short, sim)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # Validation\n    val_auc = validate(model, val_loader)\n    print(f\"Epoch {epoch+1}: Val AUC={val_auc:.4f}\")\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), '/kaggle/working/best_model_try5.pth')\n        print(f\"↳ New best model saved (AUC={val_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:57:33.319230Z","iopub.execute_input":"2025-05-04T13:57:33.319522Z","iopub.status.idle":"2025-05-04T14:10:53.286128Z","shell.execute_reply.started":"2025-05-04T13:57:33.319502Z","shell.execute_reply":"2025-05-04T14:10:53.285227Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Val AUC=0.5132\n↳ New best model saved (AUC=0.5132)\nEpoch 2: Val AUC=0.5155\n↳ New best model saved (AUC=0.5155)\nEpoch 3: Val AUC=0.5130\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/882244830.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/3982082933.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Get EEG segments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mgreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meeg_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Get handcrafted features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2842790859.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mseg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mseg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove if there's a dim of 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             raise TypeError(\"Accessing a group is done with bytes or str, \"\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5i.pyx\u001b[0m in \u001b[0;36mh5py.h5i.wrap_identifier\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha  # Weight for class 1 (P300)\n        self.gamma = gamma  # Focusing parameter\n\n    def forward(self, inputs, targets):\n        BCE_loss = nn.functional.binary_cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)  # pt = p if y=1, else 1-p\n        loss = (self.alpha * (1-pt)**self.gamma * BCE_loss).mean()\n        return loss\n\n#criterion = FocalLoss(alpha=3850/(1590+3850))  # ~0.71 for class 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:47:24.053047Z","iopub.execute_input":"2025-05-04T17:47:24.053288Z","iopub.status.idle":"2025-05-04T17:47:24.058446Z","shell.execute_reply.started":"2025-05-04T17:47:24.053272Z","shell.execute_reply":"2025-05-04T17:47:24.057613Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train_model(train_loader, val_loader, device, n_epochs=20):\n    # Initialize\n    pretrained_eeg = P300Detector().to(device)\n    pretrained_eeg.load_state_dict(torch.load('/kaggle/input/bci-rnn-raw-data/best_model_try4.pth'))\n    model = NickNet(pretrained_eeg).to(device)\n    \n    # Phase 1: Warm-up (3 epochs)\n    print(\"=== Phase 1: Warm-up ===\")\n    optimizer = torch.optim.AdamW([\n        {'params': model.feature_processor.parameters(), 'lr': 1e-3},\n        {'params': model.fusion.parameters(), 'lr': 1e-3},\n        {'params': model.classifier.parameters(), 'lr': 1e-3}\n    ], weight_decay=1e-4)\n\n    #alpha = label_stats[1][1]/(label_stats[1][0]+label_stats[1][1])\n    criterion = nn.BCELoss()\n    #criterion = FocalLoss(alpha=alpha)\n    best_auc = 0.0\n    \n    for epoch in range(n_epochs):\n        # Training\n        model.train()\n        train_loss = 0.0\n        for batch in train_loader:\n            green, blink, feedback, session, trial, is_short, sim, labels = batch\n            inputs = feedback.to(device)\n            session = session.to(device)\n            trial = trial.to(device)\n            is_short = is_short.to(device)\n            sim = sim.to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs, session, trial, is_short, sim)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            train_loss += loss.item()\n        \n        # Validation\n        val_auc = validate(model, val_loader)\n        train_loss /= len(train_loader)\n        print(f\"Epoch {epoch+1}/{n_epochs} | Train Loss: {train_loss:.4f} | Val AUC: {val_auc:.4f}\")\n        \n        # Save best model\n        if val_auc > best_auc:\n            best_auc = val_auc\n            torch.save(model.state_dict(), '/kaggle/working/best_nicknet.pth')\n            print(f\"↳ New best model saved (AUC: {best_auc:.4f})\")\n        \n        # Phase transition\n        if epoch == 2:  # After 3 warm-up epochs\n            print(\"\\n=== Phase 2: Fine-tuning ===\")\n            # Unfreeze P300Detector's head\n            for name, param in model.eeg_net.named_parameters():\n                if 'head' in name:\n                    param.requires_grad = True\n            \n            optimizer = torch.optim.AdamW([\n                {'params': model.feature_processor.parameters(), 'lr': 5e-4},\n                {'params': model.fusion.parameters(), 'lr': 5e-4},\n                {'params': model.classifier.parameters(), 'lr': 5e-4},\n                {'params': model.eeg_net.head.parameters(), 'lr': 1e-5}\n            ], weight_decay=1e-4)\n            \n            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n                optimizer, mode='max', factor=0.5, patience=2\n            )\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:28:30.298551Z","iopub.execute_input":"2025-05-04T14:28:30.298825Z","iopub.status.idle":"2025-05-04T14:28:30.308531Z","shell.execute_reply.started":"2025-05-04T14:28:30.298807Z","shell.execute_reply":"2025-05-04T14:28:30.307746Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"trained_model = train_model(train_loader, val_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:28:33.902689Z","iopub.execute_input":"2025-05-04T14:28:33.903154Z","iopub.status.idle":"2025-05-04T15:42:30.807713Z","shell.execute_reply.started":"2025-05-04T14:28:33.903130Z","shell.execute_reply":"2025-05-04T15:42:30.806943Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2671662887.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  pretrained_eeg.load_state_dict(torch.load('/kaggle/input/bci-rnn-raw-data/best_model_try4.pth'))\n","output_type":"stream"},{"name":"stdout","text":"=== Phase 1: Warm-up ===\nEpoch 1/20 | Train Loss: 0.6224 | Val AUC: 0.6720\n↳ New best model saved (AUC: 0.6720)\nEpoch 2/20 | Train Loss: 0.5826 | Val AUC: 0.6662\nEpoch 3/20 | Train Loss: 0.5693 | Val AUC: 0.6756\n↳ New best model saved (AUC: 0.6756)\n\n=== Phase 2: Fine-tuning ===\nEpoch 4/20 | Train Loss: 0.5629 | Val AUC: 0.6776\n↳ New best model saved (AUC: 0.6776)\nEpoch 5/20 | Train Loss: 0.5587 | Val AUC: 0.6793\n↳ New best model saved (AUC: 0.6793)\nEpoch 6/20 | Train Loss: 0.5600 | Val AUC: 0.6712\nEpoch 7/20 | Train Loss: 0.5543 | Val AUC: 0.6825\n↳ New best model saved (AUC: 0.6825)\nEpoch 8/20 | Train Loss: 0.5553 | Val AUC: 0.6785\nEpoch 9/20 | Train Loss: 0.5517 | Val AUC: 0.6814\nEpoch 10/20 | Train Loss: 0.5524 | Val AUC: 0.6791\nEpoch 11/20 | Train Loss: 0.5527 | Val AUC: 0.6829\n↳ New best model saved (AUC: 0.6829)\nEpoch 12/20 | Train Loss: 0.5484 | Val AUC: 0.6831\n↳ New best model saved (AUC: 0.6831)\nEpoch 13/20 | Train Loss: 0.5492 | Val AUC: 0.6737\nEpoch 14/20 | Train Loss: 0.5455 | Val AUC: 0.6713\nEpoch 15/20 | Train Loss: 0.5480 | Val AUC: 0.6807\nEpoch 16/20 | Train Loss: 0.5482 | Val AUC: 0.6802\nEpoch 17/20 | Train Loss: 0.5445 | Val AUC: 0.6772\nEpoch 18/20 | Train Loss: 0.5483 | Val AUC: 0.6833\n↳ New best model saved (AUC: 0.6833)\nEpoch 19/20 | Train Loss: 0.5426 | Val AUC: 0.6838\n↳ New best model saved (AUC: 0.6838)\nEpoch 20/20 | Train Loss: 0.5448 | Val AUC: 0.6862\n↳ New best model saved (AUC: 0.6862)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"pretrained_eeg = P300Detector().to(device)\npretrained_eeg.load_state_dict(torch.load('/kaggle/input/bci-rnn-raw-data/best_model_try4.pth'))\nmodel = NickNet(pretrained_eeg).to(device)\nmodel.load_state_dict(torch.load('/kaggle/input/bci-rnn-raw-data/best_nicknet.pth'))\nmodel.freeze_eeg_net(True)\nalpha = label_stats[1][1]/(label_stats[1][0]+label_stats[1][1])\ncriterion = FocalLoss(alpha=alpha)\n\n# Use lower LR for fine-tuning\noptimizer = torch.optim.AdamW([\n    {'params': model.feature_processor.parameters(), 'lr': 1e-5},\n    {'params': model.fusion.parameters(), 'lr': 1e-5},\n    {'params': model.classifier.parameters(), 'lr': 1e-5},\n    {'params': model.eeg_net.parameters(), 'lr': 1e-6}  # Very low LR for frozen parts\n])\n\ndef warmup_lr(epoch, warmup_epochs=2, base_lr=1e-5):\n    return base_lr * min(1.0, (epoch + 1) / warmup_epochs)\n\nbest_auc = 0.0\nprint(\"=====[ Phase 1 - LR Warmup ]=====\")\nfor epoch in range(10):\n    train_loss = 0.0\n    # --- Phase 1: Warmup (epochs 0-1) ---\n    if epoch < 2:\n        # Apply warmup ONLY to non-EEG layers\n        current_lr = warmup_lr(epoch)\n        for i, param_group in enumerate(optimizer.param_groups[:-1]):  # Exclude EEG net\n            param_group['lr'] = current_lr\n    \n    # --- Phase 2: Unfreeze (epoch >= 2) ---\n    elif epoch == 2:\n        model.freeze_eeg_net(False)  # Unfreeze EEG net\n        print(\"=====[ Phase 2 - Unfreezing EEG net layers ]=====\")\n    \n    # --- Training ---\n    model.train()\n    for batch in balanced_loader:\n        optimizer.zero_grad()\n        green, blink, feedback, session, trial, is_short, sim, labels = batch\n        outputs = model(feedback.to(device), \n                       session.to(device), \n                       trial.to(device), \n                       is_short.to(device), \n                       sim.to(device))\n        loss = criterion(outputs, labels.to(device))\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        train_loss += loss.item()\n    \n    # Validation\n    val_auc = validate(model, val_loader)\n    train_loss /= len(balanced_loader)\n    print(f\"Epoch {epoch+1}: Loss={train_loss:.4f}, Val AUC={val_auc:.4f}\")\n\n    # Save best model\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), '/kaggle/working/best_nicknet2.pth')\n        print(f\"↳ New best model saved (AUC: {best_auc:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:15:36.972863Z","iopub.execute_input":"2025-05-04T18:15:36.973402Z","iopub.status.idle":"2025-05-04T18:45:59.059309Z","shell.execute_reply.started":"2025-05-04T18:15:36.973379Z","shell.execute_reply":"2025-05-04T18:45:59.058505Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3528617432.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  pretrained_eeg.load_state_dict(torch.load('/kaggle/input/bci-rnn-raw-data/best_model_try4.pth'))\n/tmp/ipykernel_31/3528617432.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/input/bci-rnn-raw-data/best_nicknet.pth'))\n","output_type":"stream"},{"name":"stdout","text":"=====[ Phase 1 - LR Warmup ]=====\nEpoch 1: Loss=0.2427, Val AUC=0.6874\n↳ New best model saved (AUC: 0.6874)\nEpoch 2: Loss=0.2377, Val AUC=0.6876\n↳ New best model saved (AUC: 0.6876)\n=====[ Phase 2 - Unfreezing EEG net layers ]=====\nEpoch 3: Loss=0.2319, Val AUC=0.6874\nEpoch 4: Loss=0.2215, Val AUC=0.6874\nEpoch 5: Loss=0.2235, Val AUC=0.6875\nEpoch 6: Loss=0.2232, Val AUC=0.6878\n↳ New best model saved (AUC: 0.6878)\nEpoch 7: Loss=0.2173, Val AUC=0.6877\nEpoch 8: Loss=0.2165, Val AUC=0.6877\nEpoch 9: Loss=0.2146, Val AUC=0.6871\nEpoch 10: Loss=0.2125, Val AUC=0.6879\n↳ New best model saved (AUC: 0.6879)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/working/best_nicknet2.pth'))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}